# NLI_Using_Roberta-base
Natural language inference is the task of determining whether a “hypothesis” is true
(entailment), false (contradiction), or undetermined (neutral) given a “premise”. Here, I
am going to use the subset of Stanford Natural Language Inference (SNLI) Corpus containing
around 550k hypothesis/premise pairs.


The data is being uploaded to drive and being consumed by mounting google drive, this way of getting i/p files can be modified as per coder's interest.

Code mainly focuses on training the model using Roberta-base

Significant observations on optimizers, learning rate schedulers was performed.

Will encourage and accept any tuning of hyper parameters for training better models :)
